
# -*- coding: utf-8 -*-

# CrossSection
# 
import numpy as np
import pandas as pd
import statsmodels.formula.api as smf

class CrossSection():
    def __init__(self, base_data):
        '''
        func: å¯¹è¾“å…¥çš„æ•°æ®dfä»¥å¸‚å€¼ä¸ºæƒé‡è¿›è¡ŒWLSå›å½’ï¼Œè¾“å‡ºå› å­æ”¶ç›Šå’Œç‰¹æ®Šæ”¶ç›Š
        input: base_data: DataFrame(columns: date, stocknames, capital, ret, industry_factors and style_factors)
        output: å› å­æ”¶ç›Šfactor_ret, ç‰¹æ®Šæ”¶ç›Šspecific_ret, R2
        '''
        self.data = base_data
        self.stocknames = list(base_data.stocknames)          #è‚¡ç¥¨å
        self.date = list(base_data.date)[0]                   #æ—¥æœŸ
        self.capital = base_data.capital.values               #å¸‚å€¼
        self.ret = base_data.ret.values                       #t+1æœŸæ”¶ç›Šç‡
        self.W = np.sqrt(self.capital) / sum(np.sqrt(self.capital))   #åŠ æƒæœ€å°äºŒä¹˜æ³•çš„æƒé‡
        
        print('\rCross Section Regression, ' + 'Date: ' + self.date  + ', ', end = '')
        WLS = LinearRegression(fit_intercept=False)
        WLS.fit(self.data.iloc[:,4:], self.data.iloc[:,3], sample_weight = self.W)
        
        factor_ret = WLS.coef_                    #çº¯å› å­æ”¶ç›Š
        specific_ret = self.ret - WLS.predict(self.data.iloc[:,4:])             #ä¸ªè‚¡ç‰¹å¼‚æ€§æ”¶ç›Š
        R2 = 1 - np.var(specific_ret) / np.var(self.ret)                            #R square
        
        return((factor_ret, specific_ret, R2))
    
    

class MFM():
    '''
    data: DataFrame
    column1: date
    colunm2: stocknames
    colunm3: capital
    column4: ret
    style_factors: DataFrame
    industry_factors: DataFrame
    '''
    
    def __init__(self, data, P, Q):
        '''
        func: åˆå§‹åŒ–
        input: data: DataFrame(columns: date, stocknames, capital, ret, industry_factors and style_factors)
            P: industry_factors æ•°é‡
            Q: style_factors é£æ ¼å› å­æ•°é‡
        output: æ— 
        '''
        self.Q = Q                                                           #é£æ ¼å› å­æ•°
        self.P = P                                                           #è¡Œä¸šå› å­æ•°
        self.dates = pd.to_datetime(data.date.values)                        #æ—¥æœŸ
        self.sorted_dates = pd.to_datetime(np.sort(pd.unique(self.dates)))   #æ’åºåçš„æ—¥æœŸ
        self.T = len(self.sorted_dates)                                      #æœŸæ•°
        self.data = data                                                     #æ•°æ®
        self.columns = ['country']                                           #å› å­å
        self.columns.extend((list(data.columns[4:])))
        
        self.last_capital = None                                             #æœ€åä¸€æœŸçš„å¸‚å€¼ 
        self.factor_ret = None                                               #å› å­æ”¶ç›Š
        self.specific_ret = None                                             #ç‰¹å¼‚æ€§æ”¶ç›Š
        self.R2 = None                                                       #R2
        
        self.Newey_West_cov = None                        #é€æ—¶é—´ç‚¹è¿›è¡ŒNewey Westè°ƒæ•´åçš„å› å­åæ–¹å·®çŸ©é˜µ
        self.eigen_risk_adj_cov = None                    #é€æ—¶é—´ç‚¹è¿›è¡ŒEigenfactor Riskè°ƒæ•´åçš„å› å­åæ–¹å·®çŸ©é˜µ
        self.vol_regime_adj_cov = None                    #é€æ—¶é—´ç‚¹è¿›è¡ŒVolatility Regimeè°ƒæ•´åçš„å› å­åæ–¹å·®çŸ©é˜µ
    
    
    def reg_by_time(self):
        '''
        func: è°ƒç”¨ä¹‹å‰çš„CrossSectionç±»ï¼Œé€æ—¶é—´ç‚¹è¿›è¡Œæ¨ªæˆªé¢å¤šå› å­å›å½’
        output: å› å­æ”¶ç›Šfactor_ret, ç‰¹æ®Šæ”¶ç›Šspecific_ret, R2
        '''
        factor_ret = []
        R2 = []
        specific_ret = []
        
        print('===================================é€æ—¶é—´ç‚¹è¿›è¡Œæ¨ªæˆªé¢å¤šå› å­å›å½’===================================')       
        for t in range(self.T):
            data_by_time = self.data.iloc[self.dates == self.sorted_dates[t],:]
            data_by_time = data_by_time.sort_values(by = 'stocknames')
            
            cs = CrossSection(data_by_time)
            factor_ret_t, specific_ret_t , R2_t = cs.reg()
            
            factor_ret.append(factor_ret_t)
            #æ³¨æ„ï¼šæ¯ä¸ªæˆªé¢ä¸Šè‚¡ç¥¨æ± å¯èƒ½ä¸åŒ
            specific_ret.append(specific_ret_t)
            R2.append(R2_t)
            self.last_capital = cs.capital
        factor_ret = pd.DataFrame(factor_ret, columns = self.columns, index = self.sorted_dates)
        R2 = pd.DataFrame(R2, columns = ['R2'], index = self.sorted_dates)
        specific_ret = pd.DataFrame(specific_ret, columns = cs.stocknames, index = self.sorted_dates)
        self.factor_ret = factor_ret                                               #å› å­æ”¶ç›Š
        self.specific_ret = specific_ret                                           #ç‰¹å¼‚æ€§æ”¶ç›Š
        self.R2 = R2                                                               #R2
        return((factor_ret, specific_ret, R2))


    def Newey_West_by_time(self, q = 2, tao = 252, content = 'factor_ret'):
        '''
        func: é€æ—¶é—´ç‚¹è®¡ç®—åæ–¹å·®å¹¶è¿›è¡ŒNewey Westè°ƒæ•´
        input: q: å‡è®¾å› å­æ”¶ç›Šä¸ºqé˜¶MAè¿‡ç¨‹
            tao: ç®—åæ–¹å·®æ—¶çš„åŠè¡°æœŸ
            content: åŒºåˆ«å¼€å› å­æ”¶ç›Šå’Œç‰¹æ®Šæ”¶ç›Š
        output: Newey Westè°ƒæ•´åçš„df
        '''
        if content == 'factor_ret' : 
            if self.factor_ret is None:
                raise Exception('please run reg_by_time to get factor returns first')

            Newey_West_cov = []
            print('\n\n===================================é€æ—¶é—´ç‚¹è¿›è¡ŒNewey Westè°ƒæ•´=================================')    
            for t in range(1,self.T+1):
                try:
                    Newey_West_cov.append(Newey_West(self.factor_ret[:t], q, tao))
                except:
                    Newey_West_cov.append(pd.DataFrame())

                progressbar(t, self.T, '   date: ' + str(self.sorted_dates[t-1])[:10])

            self.Newey_West_cov = Newey_West_cov
            return(Newey_West_cov)
        if content == 'specific_ret' : 
            if self.specific_ret is None:
                raise Exception('please run reg_by_time to get specific returns first')

            Newey_West_cov = []
            print('\n\n===================================é€æ—¶é—´ç‚¹è¿›è¡ŒNewey Westè°ƒæ•´=================================')    
            for t in range(1,self.T+1):
                try:
                    Newey_West_cov.append(Newey_West(self.specific_ret[:t], q=5, tao=90))
                except:
                    Newey_West_cov.append(pd.DataFrame())

                progressbar(t, self.T, '   date: ' + str(self.sorted_dates[t-1])[:10])

            self.Newey_West_cov = Newey_West_cov
            return(Newey_West_cov)
    
    
    def eigen_risk_adj_by_time(self, M = 100, scale_coef = 1.4):
        '''
        func: é€æ—¶é—´ç‚¹è¿›è¡ŒEigenfactor Risk Adjustment
        input: M: æ¨¡æ‹Ÿæ¬¡æ•°
            scale_coef: scale coefficient for bias(ç ”æŠ¥å»ºè®®ä¸º1.4)
        output: Eigenfactor Risk Adjustmentåçš„df
        '''
        
        if self.Newey_West_cov is None:
            raise Exception('please run Newey_West_by_time to get factor return covariances after Newey West adjustment first')        
        
        eigen_risk_adj_cov = []
        print('\n\n===================================é€æ—¶é—´ç‚¹è¿›è¡ŒEigenfactor Riskè°ƒæ•´=================================')    
        for t in range(self.T):
            try:
                eigen_risk_adj_cov.append(eigen_risk_adj(self.Newey_West_cov[t], self.T, M, scale_coef))
            except:
                eigen_risk_adj_cov.append(pd.DataFrame())
            
            progressbar(t+1, self.T, '   date: ' + str(self.sorted_dates[t])[:10])
        
        self.eigen_risk_adj_cov = eigen_risk_adj_cov
        return(eigen_risk_adj_cov)
        
        
    
    def vol_regime_adj_by_time(self, tao = 42, h = 252, content = 'factor_ret', data_cov = None):
        '''
        func: å¯¹çŸ©é˜µè¿›è¡ŒVolatility Regime Adjustment
        input: tao: Volatility Regime Adjustmentçš„åŠè¡°æœŸ
            h: å›æµ‹å¤©æ•°
            content: åŒºåˆ«å¼€å› å­æ”¶ç›Šå’Œç‰¹æ®Šæ”¶ç›Š
            data_cov: åœ¨ç‰¹æ®Šå› å­è°ƒæ•´æ—¶éœ€è¦ç”¨åˆ°(content = 'specific_ret')ï¼Œå¦åˆ™ä¸ºNone
        '''
        if content == 'factor_ret':        
            if self.eigen_risk_adj_cov is None:
                raise Exception('please run eigen_risk_adj_by_time to get factor return covariances after eigenfactor risk adjustment first')        


            K = len(self.eigen_risk_adj_cov[-1])
            res_var = list()
            for t in range(self.T):
                res_var_i = np.diag(self.eigen_risk_adj_cov[t])
                if len(res_var_i)==0:
                    res_var_i = np.array(K*[np.nan])
                res_var.append(res_var_i)

            res_var = np.array(res_var)

            B = np.sqrt(np.mean(self.factor_ret**2 / res_var, axis = 1))      #æˆªé¢ä¸Šçš„biasç»Ÿè®¡é‡
            weights = 0.5**(np.arange(h-1,-1,-1)/tao)                            #æŒ‡æ•°è¡°å‡æƒé‡ # new : self.T : h


            lamb = []
            vol_regime_adj_cov = []
            print('\n\n==================================é€æ—¶é—´ç‚¹è¿›è¡ŒVolatility Regimeè°ƒæ•´================================') 
            for t in [self.T]:
                #å–é™¤æ— æ•ˆçš„è¡Œ
                if t <= 252 : 
                    okidx = pd.isna(res_var[:t]).sum(axis = 1) == 0 
                    okweights = weights[:t][okidx] / sum(weights[:t][okidx])
                    fvm = np.sqrt(sum(okweights * B.values[:t][okidx]**2))   #factor volatility multiplier
                else : 
                    okidx = pd.isna(res_var[t-252:t]).sum(axis = 1) == 0 
                    okweights = weights[:][okidx] / sum(weights[:][okidx])
                    fvm = np.sqrt(sum(okweights * B.values[t-252:t][okidx]**2))   #factor volatility multiplier

                lamb.append(fvm)  
                vol_regime_adj_cov.append(self.eigen_risk_adj_cov[t-1] * fvm**2)
                progressbar(t, self.T, '   date: ' + str(self.sorted_dates[t-1])[:10])

            self.vol_regime_adj_cov = vol_regime_adj_cov
            return((vol_regime_adj_cov, lamb))
        
        if content == 'specific_ret':
            res_var = list()
            weight_cap = list()
            for t in range(self.T):
                data_K = self.data[self.data['date'] == self.sorted_dates[t].strftime("%Y-%m-%d")]
                K = len(data_K)
                
                res_var_i = data_cov[t]
                weight_cap_i = data_K['capital']
                weight_cap_sum = data_K['capital'].sum()
                if len(res_var_i)==0:
                    res_var_i = np.array(K*[np.nan])
                res_var.append(res_var_i)
                weight_cap.append(weight_cap_i/weight_cap_sum)
            res_var = np.array(res_var)
            weight_cap = np.array(weight_cap)
            
            B = np.sqrt(np.sum(self.specific_ret**2 / res_var * weight_cap, axis = 1))     #æˆªé¢ä¸Šçš„biasç»Ÿè®¡é‡
            B[np.isnan(B)] = 0
            weights = 0.5**(np.arange(h-1,-1,-1)/tao)                            #æŒ‡æ•°è¡°å‡æƒé‡ # new : self.T : h

            lamb = []
            vol_regime_adj_cov = []
            print('\n\n==================================é€æ—¶é—´ç‚¹è¿›è¡ŒVolatility Regimeè°ƒæ•´================================') 
            for t in [self.T]:
                #å–é™¤æ— æ•ˆçš„è¡Œ
                if t < 253 : 
                    lamb.append([])  
                    vol_regime_adj_cov.append(pd.Series())
                else : 
                    okidx = pd.isna(res_var[t-252:t]).sum(axis = 1) == 0 
                    okweights = weights[:][okidx] / sum(weights[:][okidx])
                    fvm = np.sqrt(np.sum(okweights * B.values[t-252:t][okidx]**2))   #factor volatility multiplier
                    lamb.append(fvm)  
                    vol_regime_adj_cov.append(data_cov[t-1] * fvm)
                progressbar(t, self.T, '   date: ' + str(self.sorted_dates[t-1])[:10])

            self.vol_regime_adj_cov = vol_regime_adj_cov
            return((vol_regime_adj_cov, lamb))

        

import matplotlib.pyplot as plt
import math



def Newey_West(ret, q = 2, tao = 90, h = 252):
    '''
    func: Newey_Westæ–¹å·®è°ƒæ•´
        æ—¶åºä¸Šå­˜åœ¨ç›¸å…³æ€§æ—¶ï¼Œä½¿ç”¨Newey_Westè°ƒæ•´åæ–¹å·®ä¼°è®¡
    factor_ret: DataFrame, è¡Œä¸ºæ—¶é—´ï¼Œåˆ—ä¸ºå› å­æ”¶ç›Š
    q: å‡è®¾å› å­æ”¶ç›Šä¸ºqé˜¶MAè¿‡ç¨‹
    tao: ç®—åæ–¹å·®æ—¶çš„åŠè¡°æœŸ
    '''
    from functools import reduce
    from statsmodels.stats.weightstats import DescrStatsW 
    
    T = ret.shape[0]           #æ—¶åºé•¿åº¦
    K = ret.shape[1]           #å› å­æ•°/è‚¡ç¥¨æ•°
    if T <= q or T < h:
        raise Exception("T <= q or T < h") # new: add h
    ret = ret.iloc[-h:,:] # new: add h
    names = ret.columns    
    weights = 0.5**(np.arange(h-1,-1,-1)/tao)   #æŒ‡æ•°è¡°å‡æƒé‡ # new: T to h
    weights = weights / sum(weights)
    
    w_stats = DescrStatsW(ret, weights)
    ret = ret - w_stats.mean
    
    ret = np.matrix(ret.values)
    Gamma0 = [weights[t] * ret[t].T  @ ret[t] for t in range(h)] # new: T to h
    Gamma0 = reduce(np.add, Gamma0)
    
    
    V = Gamma0             #è°ƒæ•´åçš„åæ–¹å·®çŸ©é˜µ
    for i in range(1,q+1):
        Gammai = [weights[i+t] * ret[t].T  @ ret[i+t] for t in range(h-i)]  # new: T to h
        Gammai = reduce(np.add, Gammai)
        V = V + (1 - i/(1+q)) * (Gammai + Gammai.T)
    
    return(pd.DataFrame(V, columns = names, index = names))
    
    
    

def eigen_risk_adj(covmat, T = 100, M = 100, scale_coef = 1.2):
    '''
    func: Eigenfactor Risk Adjustment
    input: T: åºåˆ—é•¿åº¦
        M: æ¨¡æ‹Ÿæ¬¡æ•°
        scale_coef: scale coefficient for bias
    '''
    F0 = covmat
    K = covmat.shape[0]
    D0,U0 = np.linalg.eig(F0)      #ç‰¹å¾å€¼åˆ†è§£; D0æ˜¯ç‰¹å¾å› å­ç»„åˆçš„æ–¹å·®; U0æ˜¯ç‰¹å¾å› å­ç»„åˆä¸­å„å› å­æƒé‡; F0æ˜¯å› å­åæ–¹å·®æ–¹å·®
    #F0 = U0 @ D0 @ U0.T    D0 = U0.T @ F0 @ U0  
    
#     if not all(D0>=0):         #æ£€éªŒæ­£å®šæ€§
#         raise('covariance is not symmetric positive-semidefinite')
   
    v = []  #bias
    for m in range(M):
        ## æ¨¡æ‹Ÿå› å­åæ–¹å·®çŸ©é˜µ
        np.random.seed(m+1)
        bm = np.random.multivariate_normal(mean = K*[0], cov = np.diag(D0), size = T).T  #ç‰¹å¾å› å­ç»„åˆçš„æ”¶ç›Š
        fm = U0 @ bm       #åå˜æ¢å¾—åˆ°å„ä¸ªå› å­çš„æ”¶ç›Š
        Fm = np.cov(fm)    #æ¨¡æ‹Ÿå¾—åˆ°çš„å› å­åæ–¹å·®çŸ©é˜µ

        ##å¯¹æ¨¡æ‹Ÿçš„å› å­åæ–¹å·®çŸ©é˜µè¿›è¡Œç‰¹å¾åˆ†è§£
        Dm,Um = np.linalg.eig(Fm)   # Um.T @ Fm @ Um 
    
        ##æ›¿æ¢Fmä¸ºF0
        Dm_hat = Um.T @ F0 @ Um 

        v.append(np.diagonal(Dm_hat) / Dm)

    v = np.sqrt(np.mean(np.array(v), axis = 0))
    v = scale_coef * (v-1) + 1
    
    
    D0_hat = np.diag(v**2) * np.diag(D0)  #è°ƒæ•´å¯¹è§’çº¿
    F0_hat = U0 @ D0_hat @ U0.T           #è°ƒæ•´åçš„å› å­åæ–¹å·®çŸ©é˜µ
    return(pd.DataFrame(F0_hat, columns = covmat.columns, index = covmat.columns))

    


def eigenfactor_bias_stat(cov, ret, predlen = 1):
    '''
    func: è®¡ç®—ç‰¹å¾å› å­ç»„åˆçš„biasç»Ÿè®¡é‡
    '''
    #bias stat
    b = []
    for i in range(len(cov)-predlen):
        try:
            D, U = np.linalg.eig(cov[i])                              #ç‰¹å¾åˆ†è§£, Uçš„æ¯ä¸€åˆ—å°±æ˜¯ç‰¹å¾å› å­ç»„åˆçš„æƒé‡
            U = U / np.sum(U, axis = 0)                               #å°†æƒé‡æ ‡å‡†åŒ–åˆ°1
            sigma = np.sqrt(predlen * np.diag(U.T @ cov[i] @ U))      #ç‰¹å¾å› å­ç»„åˆçš„æ³¢åŠ¨ç‡
            retlen = (ret.values[(i+1):(i+predlen+1)] + 1).prod(axis=0) - 1
            r = U.T @ retlen                                          #ç‰¹å¾å› å­ç»„åˆçš„æ”¶ç›Šç‡
            b.append(r / sigma)
        except:
            pass
    
    b = np.array(b)
    bias_stat = np.std(b, axis = 0)
    plt.plot(bias_stat)
    return(bias_stat)
    


    
def progressbar(cur, total, txt):
    '''
    func: æ˜¾ç¤ºè¿›åº¦æ¡
    '''
    percent = '{:.2%}'.format(cur / total)
    print("\r[%-50s] %s" % ('=' * int(math.floor(cur * 50 / total)), percent) + txt, end = '')
    



def group_mean_std(x):
    '''
    func: è®¡ç®—ä¸€ç»„çš„åŠ æƒå¹³å‡å’Œæ³¢åŠ¨ç‡
    '''
    m =sum(x.volatility*x.capital) / sum(x.capital)
    s = np.sqrt(np.mean((x.volatility - m)**2))
    return([m, s])


def shrink(x, group_weight_mean, q):
    '''
    func: è®¡ç®—shrinkä¼°è®¡é‡
    '''
    a = q * np.abs(x['volatility'] - group_weight_mean[x['group']][0])
    b =  group_weight_mean[x['group']][1]
    v = a / (a + b)     #æ”¶ç¼©å¼ºåº¦
    SH_est = v * group_weight_mean[x['group']][0] + (1-v) * np.abs(x['volatility'])    #è´å¶æ–¯æ”¶ç¼©ä¼°è®¡é‡
    return(SH_est)
    

def bayes_shrink(volatility, capital, ngroup = 10, q = 1):
    '''
    func: ä½¿ç”¨å¸‚å€¼å¯¹ç‰¹å¼‚æ€§æ”¶ç›Šç‡æ³¢åŠ¨ç‡è¿›è¡Œè´å¶æ–¯æ”¶ç¼©ï¼Œä»¥ä¿è¯æ³¢åŠ¨ç‡ä¼°è®¡åœ¨æ ·æœ¬å¤–çš„æŒç»­æ€§
    input: volatility: æ³¢åŠ¨ç‡
        capital: å¸‚å€¼
        ngroup: åˆ’åˆ†çš„ç»„æ•°
        q: shrinkage parameter
    '''
    group = pd.qcut(capital,  10, [1,2,3,4,5,6,7,8,9,10]).values   #æŒ‰ç…§å¸‚å€¼åˆ†ä¸º10ç»„
    data = pd.DataFrame(np.array([volatility, capital, group]).T, columns = ['volatility', 'capital', 'group'])
    #åˆ†ç»„è®¡ç®—åŠ æƒå¹³å‡
    grouped = data.groupby('group')
    group_weight_mean = grouped.apply(group_mean_std)
    
    SH_est = data.apply(shrink, axis = 1, args = (group_weight_mean, q))   #è´å¶æ–¯æ”¶ç¼©ä¼°è®¡é‡ 
    SH_est.index = capital.index
    return(SH_est)


def structural_model(i, data_t, sigma_NW, h = 252):
    """
    func: å¯¹dataè¿›è¡Œç»“æ„åŒ–è°ƒæ•´
    ret = specific_ret
    """
    # ï¼ˆ1ï¼‰é¦–å…ˆè®¡ç®—æ¯åªè‚¡ç¥¨ç‰¹å¼‚æ”¶ç›Šçš„ç¨³å¥æ ‡å‡†å·®ğœÌƒuï¼š
    sigma_u = (1/1.35) * ( ret.iloc[-h:,:].quantile(3/4) - ret.iloc[-h:,:].quantile(1/4) )
    # è®¡ç®—ğœğ‘¢,ğ‘’ğ‘ï¼Œç‰¹å¼‚æ”¶ç›Šçš„æ ·æœ¬æ ‡å‡†å·®
    sigma_ueq = ret.std(axis=0,ddof=1)
    # è®¡ç®—ç‰¹å¼‚æ”¶ç›Šçš„è‚¥å°¾ç¨‹åº¦æŒ‡æ ‡ğ‘uã€‚è‹¥ğ‘ğ‘¢å€¼è¿‡å¤§ï¼Œåˆ™è¯´æ˜è¯¥ç‰¹å¼‚æ”¶ç›Šåºåˆ—ä¸­å­˜åœ¨å¼‚å¸¸å€¼ã€‚
    z_u = abs( (sigma_ueq - sigma_u) / sigma_u )

    t = np.exp(1 - z_u)
    t[t<=0] = 0  # max(0, np.exp(1 - z_u))
    t[t>=1] = 1  # min(1,x)
    # å¼•å…¥åè°ƒå‚æ•°Î³
    gamma = (min(1,max(0, (h-60)/120))) * t
    list_i = list(set(gamma[gamma==1].index.to_list()).intersection(set(data_t['stocknames'].to_list())).intersection(set(sigma_NW.index.to_list()))) # å–äº¤é›†ï¼Œåç»­åˆ é™¤

    sigma_NW = sigma_NW
    sigma_TR = np.diag(sigma_NW)
    sigma_TR = pd.Series(sigma_TR,index = sigma_NW.index)
    sigma_TR = sigma_TR[list_i]

    reg_t = data_t.set_index('stocknames')
    reg_t = reg_t.loc[list_i,:].iloc[:,3:]
    reg_t['sigma_TR'] = np.log(sigma_TR)  # np.ln(sigma_TR)

    # æ”¹ä¸ºWLSå›å½’
    W_df = data[data['date'] == data.iloc[-1]['date']].set_index('stocknames')
    W_df = W_df.loc[list_i]
    capital = W_df.capital.values             #å¸‚å€¼
    W = np.sqrt(capital) / sum(np.sqrt(capital))   #åŠ æƒæœ€å°äºŒä¹˜æ³•çš„æƒé‡
    WLS = LinearRegression()
    WLS.fit((reg_t.iloc[:,:-1]), (reg_t.iloc[:,-1]), sample_weight = W)
#     smf_X = np.matrix(reg_t.iloc[:,:-1])
#     smf_y = np.matrix(reg_t.iloc[:,-1]).T
#     b_k = (smf_X.T @ smf_X).I @ smf_X.T @ smf_y
    b_k = WLS.coef_
    b_k = np.array(b_k.reshape(1,37))[0]
    data_t = data_t.iloc[:,4:]
    sigma_STR = (data_t.apply(lambda x : np.exp((x * b_k).sum()),axis = 1)) * 1.05
    res = np.array(gamma) * np.diag(sigma_NW) + np.array(1 - gamma) * np.array(sigma_STR)
    res = pd.Series(res, index = gamma.index)
    return res


def min_vol_fac_port(V, X, factor_k):
    """
    func: è¾“å‡ºæœ€å°æ³¢åŠ¨ç»„åˆ
    input: V: è‚¡ç¥¨æ”¶ç›Šçš„åæ–¹å·®çŸ©é˜µï¼ˆNÃ—N ç»´ï¼‰ dataframe
        X: è‚¡ç¥¨å› å­æš´éœ²çŸ©é˜µï¼ˆNÃ—Kç»´ï¼‰ dataframe 
        X_k: è¡¨ç¤ºè‚¡ç¥¨åœ¨å› å­kä¸Šçš„æš´éœ²åº¦ï¼ˆNÃ—1ç»´ï¼‰ dataframe 
        factor_k: å› å­k list
    """
    
    stks_i = V.index
    X = X.loc[stks_i,:]
    import numpy.linalg as lg
    X_k = X[factor_k]
    V = np.matrix(V.values)
    X_k = np.matrix(X_k.values)

    V[np.isnan(V)] = 0

    res = (V.I @ X_k) / (X_k.T @ V.I @ X_k).diagonal()
    return(pd.DataFrame(res, columns = factor_k, index = stks_i))
