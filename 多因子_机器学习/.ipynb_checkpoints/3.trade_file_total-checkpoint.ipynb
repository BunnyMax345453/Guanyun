{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T06:23:25.864221Z",
     "start_time": "2021-12-13T06:20:30.387796Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta.csv\n",
      "book_to_price_ratio.csv\n",
      "earnings_yield.csv\n",
      "growth.csv\n",
      "leverage.csv\n",
      "liquidity.csv\n",
      "momentum.csv\n",
      "non_linear_size.csv\n",
      "residual_volatility.csv\n",
      "size.csv\n",
      "alpha_001.csv\n",
      "alpha_002.csv\n",
      "alpha_003.csv\n",
      "alpha_004.csv\n",
      "alpha_005.csv\n",
      "alpha_006.csv\n",
      "alpha_007.csv\n",
      "alpha_008.csv\n",
      "alpha_009.csv\n",
      "alpha_010.csv\n",
      "alpha_011.csv\n",
      "alpha_012.csv\n",
      "alpha_013.csv\n",
      "alpha_014.csv\n",
      "alpha_015.csv\n",
      "alpha_016.csv\n",
      "alpha_017.csv\n",
      "alpha_018.csv\n",
      "alpha_019.csv\n",
      "alpha_020.csv\n",
      "alpha_021.csv\n",
      "alpha_022.csv\n",
      "alpha_023.csv\n",
      "alpha_024.csv\n",
      "alpha_025.csv\n",
      "alpha_026.csv\n",
      "alpha_027.csv\n",
      "alpha_028.csv\n",
      "alpha_029.csv\n",
      "alpha_030.csv\n"
     ]
    }
   ],
   "source": [
    "# import Ipynb_importer\n",
    "import pandas as pd\n",
    "import prepare_data_file\n",
    "features_df, targets_df = prepare_data_file.prepare_data_func(factor = 'alpha101')\n",
    "sorted_date = sorted(targets_df.date.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T03:24:17.774020Z",
     "start_time": "2021-12-13T03:23:08.858961Z"
    }
   },
   "outputs": [],
   "source": [
    "features_df.to_csv('features_df2.csv')\n",
    "targets_df.to_csv('targets_df2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data and para"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T06:23:58.524545Z",
     "start_time": "2021-12-12T06:23:50.353440Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "features_df = pd.read_csv('features_df2.csv').set_index('Unnamed: 0')\n",
    "targets_df = pd.read_csv('targets_df2.csv').set_index('Unnamed: 0')\n",
    "sorted_date = sorted(targets_df.date.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T06:23:26.473589Z",
     "start_time": "2021-12-13T06:23:26.465609Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'lgb' : {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',  # F1 accu ##################### \n",
    "        'is_unbalance': 'true', \n",
    "        'boosting': 'gbdt',\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.5,\n",
    "        'bagging_freq': 20,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_bin':255,\n",
    "        'num_leaves': 64,\n",
    "        'max_depth': 7,  # 太多了，一般3-5  <7\n",
    "        'verbose': -1,\n",
    "    },\n",
    "    'nn' : {\n",
    "        'units': 32, \n",
    "        'epochs': 100, \n",
    "        'batch_size': 32768,\n",
    "        'verbose': 0,\n",
    "        'loss':'mse',\n",
    "        'optimizer':'adam',\n",
    "        'input':len(features_df.columns)-2,\n",
    "    },\n",
    "    'lr' : {\n",
    "        'C': 0.01, \n",
    "        'class_weight': 'balanced', \n",
    "        'dual': False, \n",
    "        'fit_intercept': True, \n",
    "        'intercept_scaling': 1, \n",
    "        'l1_ratio': None, \n",
    "        'max_iter': 500, \n",
    "        'multi_class': 'auto', \n",
    "        'n_jobs': -1, \n",
    "        'penalty': 'l1', \n",
    "        'random_state': None, \n",
    "        'solver': 'liblinear', \n",
    "        'tol': 0.0001, \n",
    "        'verbose': 0,\n",
    "        'warm_start': False,\n",
    "    },\n",
    "    'cnn':{\n",
    "        'input':len(features_df.columns)-2,\n",
    "    },\n",
    "    'linear_reg':{},\n",
    "    'svm':{\n",
    "        'C': 0.6, \n",
    "        'break_ties': False, \n",
    "        'cache_size': 2000, \n",
    "        'class_weight': None, \n",
    "        'coef0': 0, \n",
    "        'decision_function_shape': 'ovr',\n",
    "        'degree': 3,\n",
    "        'gamma': 1, \n",
    "        'kernel': 'rbf',\n",
    "        'max_iter': 500, \n",
    "        'probability': False,\n",
    "        'random_state': None, \n",
    "        'shrinking': True, \n",
    "        'tol': 0.001,\n",
    "        'verbose': False\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T08:57:43.754635Z",
     "start_time": "2021-12-13T06:23:27.737207Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-03-11\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2013-04-12\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2013-05-17\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2013-06-21\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2013-07-23\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2013-08-22\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2013-09-25\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2013-11-01\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2013-12-03\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2014-01-03\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2014-02-11\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2014-03-13\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2014-04-15\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2014-05-19\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2014-06-19\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2014-07-21\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2014-08-20\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2014-09-22\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2014-10-29\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2014-11-28\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2014-12-30\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2015-02-02\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2015-03-11\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2015-04-13\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2015-05-14\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2015-06-15\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2015-07-16\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2015-08-17\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2015-09-18\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2015-10-27\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2015-11-26\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2015-12-28\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2016-01-28\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2016-03-07\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2016-04-07\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2016-05-10\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2016-06-13\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2016-07-13\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2016-08-12\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2016-09-13\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2016-10-24\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2016-11-23\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2016-12-23\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2017-01-25\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2017-03-03\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2017-04-06\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2017-05-09\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2017-06-12\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2017-07-12\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2017-08-11\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2017-09-12\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2017-10-19\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2017-11-20\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2017-12-20\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2018-01-22\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2018-02-28\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2018-03-30\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2018-05-07\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2018-06-06\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2018-07-09\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2018-08-08\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2018-09-07\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2018-10-17\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2018-11-16\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2018-12-18\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2019-01-21\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2019-02-27\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2019-03-29\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2019-05-06\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2019-06-05\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2019-07-08\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2019-08-07\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2019-09-06\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2019-10-16\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2019-11-15\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2019-12-17\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2020-01-17\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2020-02-26\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2020-03-27\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2020-04-29\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2020-06-03\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2020-07-07\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2020-08-06\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2020-09-07\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2020-10-15\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2020-11-16\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2020-12-16\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2021-01-18\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2021-02-24\n",
      "lgb\n",
      "nn\n",
      "lr\n",
      "2021-03-26\n",
      "lgb\n",
      "nn\n",
      "lr\n"
     ]
    }
   ],
   "source": [
    "interval = 22\n",
    "T_total = len(targets_df.date.unique())//interval\n",
    "\n",
    "import factor_analysis_file\n",
    "import ml2\n",
    "import numpy as np\n",
    "method_list = ['lgb','nn','lr']\n",
    "# method_list = ['cnn']\n",
    "factor_total_dict = {}.fromkeys(method_list,pd.DataFrame())\n",
    "\n",
    "# close_df = pd.read_csv('收盘价(元).csv').set_index('date')\n",
    "for T in range((252*2)//interval + 2, T_total):\n",
    "    T = interval * T\n",
    "    date_train = sorted_date[T - 252 : T - 21-7]  # 过去一年  #########################  √\n",
    "    date_valid = sorted_date[T - 21-7 : T-7]\n",
    "    date_test = sorted_date[T : T+22]\n",
    "    print(sorted_date[T])\n",
    "    x_train = features_df[features_df['date'].isin(date_train)].iloc[:,2:]\n",
    "    x_valid = features_df[features_df['date'].isin(date_valid)].iloc[:,2:]\n",
    "    x_test = features_df[features_df['date'].isin(date_test)].iloc[:,2:]\n",
    "    y_train = targets_df[targets_df['date'].isin(date_train)]\n",
    "    y_valid = targets_df[targets_df['date'].isin(date_valid)]\n",
    "    y_test = targets_df[targets_df['date'].isin(date_test)]\n",
    "\n",
    "    ## 运行机器学习函数，输出model.probs或其他结果，只有stock相关的一列数据\n",
    "    for method in method_list:\n",
    "        print(method)\n",
    "        targets_test_df = targets_df[targets_df['date'].isin(date_test)]\n",
    "        test_predict = ml2.ml(method,(x_train,x_valid,x_test), (y_train,y_valid,y_test), parameters[method],delay=0)\n",
    "        # IC分布 每天横截面的IC 一年252IC #  IR #####################\n",
    "    #     test_predict = (test_predict - np.mean(test_predict))/np.std(test_predict)  # 每天nom  ###########################\n",
    "        targets_test_df['predict'] = test_predict\n",
    "        targets_test_df['predict'] = targets_test_df['predict'].groupby(targets_test_df['date']).transform(lambda x:(x - np.mean(x))/np.std(x)) # 每天nom\n",
    "        factor_df = targets_test_df.pivot('date','stockname','predict')\n",
    "        factor_total_dict[method] = factor_total_dict[method].append(factor_df)\n",
    "\n",
    "# factor_analysis_file添加func；IC DAILY,与第二天label的corr，timeseries 分布 ###############\n",
    "# factor_total_df 总的R2  random forest reg ############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T08:57:51.997471Z",
     "start_time": "2021-12-13T08:57:44.572355Z"
    }
   },
   "outputs": [],
   "source": [
    "for key in method_list:\n",
    "    factor_total_dict[key]['date'] = factor_total_dict[key].index\n",
    "#     factor_total_dict[key].to_csv(key+'.csv')\n",
    "factor_total_dict[method]\n",
    "factor_melt_df = dict()\n",
    "for method in method_list:\n",
    "    factor_df = factor_total_dict[method]\n",
    "\n",
    "    factor_melt_df[method] = pd.melt(factor_df, \n",
    "                                id_vars=['date'], \n",
    "                                value_vars=list(factor_df.columns[1:]),\n",
    "                                var_name='stockname', \n",
    "                                value_name=method) \n",
    "    factor_melt_df[method] = factor_melt_df[method].set_index(factor_melt_df[method]['date'] + factor_melt_df[method]['stockname'])\n",
    "    factor_melt_df[method] = factor_melt_df[method].groupby(factor_melt_df[method].index).first()\n",
    "sum_df = pd.DataFrame()\n",
    "sum_df[['date','stockname']] = factor_melt_df[method][['date','stockname']]\n",
    "sum_df = sum_df.set_index(sum_df['date'] + sum_df['stockname'])\n",
    "\n",
    "for key in factor_melt_df.keys():\n",
    "    sum_df = pd.merge(sum_df, factor_melt_df[key].iloc[:,2:], how='left', left_index=True, right_index=True)\n",
    "\n",
    "sum_df.sort_values(by=['stockname', 'date'],ascending=True)\n",
    "sum_df.iloc[:,2:] = sum_df.iloc[:,2:].groupby(sum_df['stockname']).transform(lambda x:x.fillna(method='ffill')) # fillna\n",
    "sum_df = sum_df.set_index(sum_df['date'] + sum_df['stockname'])    \n",
    "\n",
    "# features_df = sum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T13:07:21.802646Z",
     "start_time": "2021-12-13T13:05:02.062544Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-05-19\n",
      "2014-06-19\n",
      "2014-07-21\n",
      "2014-08-20\n",
      "2014-09-22\n",
      "2014-10-29\n",
      "2014-11-28\n",
      "2014-12-30\n",
      "2015-02-02\n",
      "2015-03-11\n",
      "2015-04-13\n",
      "2015-05-14\n",
      "2015-06-15\n",
      "2015-07-16\n",
      "2015-08-17\n",
      "2015-09-18\n",
      "2015-10-27\n",
      "2015-11-26\n",
      "2015-12-28\n",
      "2016-01-28\n",
      "2016-03-07\n",
      "2016-04-07\n",
      "2016-05-10\n",
      "2016-06-13\n",
      "2016-07-13\n",
      "2016-08-12\n",
      "2016-09-13\n",
      "2016-10-24\n",
      "2016-11-23\n",
      "2016-12-23\n",
      "2017-01-25\n",
      "2017-03-03\n",
      "2017-04-06\n",
      "2017-05-09\n",
      "2017-06-12\n",
      "2017-07-12\n",
      "2017-08-11\n",
      "2017-09-12\n",
      "2017-10-19\n",
      "2017-11-20\n",
      "2017-12-20\n",
      "2018-01-22\n",
      "2018-02-28\n",
      "2018-03-30\n",
      "2018-05-07\n",
      "2018-06-06\n",
      "2018-07-09\n",
      "2018-08-08\n",
      "2018-09-07\n",
      "2018-10-17\n",
      "2018-11-16\n",
      "2018-12-18\n",
      "2019-01-21\n",
      "2019-02-27\n",
      "2019-03-29\n",
      "2019-05-06\n",
      "2019-06-05\n",
      "2019-07-08\n",
      "2019-08-07\n",
      "2019-09-06\n",
      "2019-10-16\n",
      "2019-11-15\n",
      "2019-12-17\n",
      "2020-01-17\n",
      "2020-02-26\n",
      "2020-03-27\n",
      "2020-04-29\n",
      "2020-06-03\n",
      "2020-07-07\n",
      "2020-08-06\n",
      "2020-09-07\n",
      "2020-10-15\n",
      "2020-11-16\n",
      "2020-12-16\n",
      "2021-01-18\n",
      "2021-02-24\n",
      "2021-03-26\n"
     ]
    }
   ],
   "source": [
    "date_2 = sorted(sum_df.date.unique())\n",
    "T_2 = len(date_2)//interval\n",
    "factor_sum_df2 = pd.DataFrame()\n",
    "method = 'lr'\n",
    "sum_df_2 = sum_df.dropna()\n",
    "targets_df_2 = targets_df.loc[sum_df_2.index,:]\n",
    "sum_df_2 = sum_df_2.loc[targets_df_2.index,:]\n",
    "for T in range(252//interval + 2, T_2):\n",
    "    T = interval * T\n",
    "    date_train = date_2[T - 252 : T - 21-7]  # 过去一年  #########################  √\n",
    "    date_valid = date_2[T - 21-7 : T-7]\n",
    "    date_test = date_2[T : T+22]\n",
    "    print(date_2[T])\n",
    "    x_train = sum_df_2[sum_df_2['date'].isin(date_train)].iloc[:,2:]\n",
    "    x_valid = sum_df_2[sum_df_2['date'].isin(date_valid)].iloc[:,2:]\n",
    "    x_test = sum_df_2[sum_df_2['date'].isin(date_test)].iloc[:,2:]\n",
    "    y_train = targets_df_2[targets_df_2['date'].isin(date_train)]\n",
    "    y_valid = targets_df_2[targets_df_2['date'].isin(date_valid)]\n",
    "    y_test = targets_df_2[targets_df_2['date'].isin(date_test)]\n",
    "\n",
    "    ## 运行机器学习函数，输出model.probs或其他结果，只有stock相关的一列数据\n",
    "    targets_test_df = targets_df_2[targets_df_2['date'].isin(date_test)]\n",
    "    test_predict = ml2.ml(method,(x_train,x_valid,x_test), (y_train,y_valid,y_test), parameters[method],delay=0)\n",
    "    # IC分布 每天横截面的IC 一年252IC #  IR #####################\n",
    "#     test_predict = (test_predict - np.mean(test_predict))/np.std(test_predict)  # 每天nom  ###########################\n",
    "    targets_test_df['predict'] = test_predict\n",
    "    targets_test_df['predict'] = targets_test_df['predict'].groupby(targets_test_df['date']).transform(lambda x:(x - np.mean(x))/np.std(x)) # 每天nom\n",
    "    factor_df = targets_test_df.pivot('date','stockname','predict')\n",
    "    factor_sum_df2 = factor_sum_df2.append(factor_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T13:07:24.438903Z",
     "start_time": "2021-12-13T13:07:23.409657Z"
    }
   },
   "outputs": [],
   "source": [
    "factor_sum_df2.to_csv('factor_sum_df3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import factor_analysis_file\n",
    "cumu_df = cumulative_return_calculate(factor_sum_df, quantiles=5,  D=1,fee=0)        \n",
    "ic_series = ic_calculate(factor_sum_df,  D=1)\n",
    "print('mean:', ic_series.mean(), 'std:', ic_series.std(), 'ir:', ic_series.mean()/ic_series.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
