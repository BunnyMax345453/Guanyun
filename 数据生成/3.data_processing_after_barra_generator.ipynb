{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "对于自定函数生成的Barra的描述因子（而非来自joinquant的数据），\n",
    "进行数据的格式整理，加入行业因子，涨跌幅，市值几个因子，\n",
    "调整格式为组合优化函数所需要的格式，\n",
    "每个月对该次分析所需要的历史数据输出csv文件保存\n",
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import akshare as ak\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats.mstats import winsorize\n",
    "import datetime\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "import alphalens\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据导入和整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T11:27:25.716668Z",
     "start_time": "2021-09-08T11:26:46.310820Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta\n",
      "blev\n",
      "btop\n",
      "cetop\n",
      "cmra\n",
      "dastd\n",
      "dtoa\n",
      "egrlf\n",
      "egro\n",
      "egrsf\n",
      "epfwd\n",
      "etop\n",
      "hsigma\n",
      "lncap\n",
      "mlev\n",
      "nlsize\n",
      "rstr\n",
      "sgro\n",
      "stoa\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of ['date'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0c7251ed9655>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles_list\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdataset_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dataset/barra factor/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'涨跌幅(%)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'总市值(元)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mset_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   4725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4726\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4727\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4729\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['date'] are in the columns\""
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "对保存的描述因子csv文件读取\n",
    "每个csv文件文件名为描述因子名.csv，列为stock，行为date\n",
    "\"\"\"\n",
    "for root, dirs, files in os.walk('dataset/barra factor'):\n",
    "    pass\n",
    "files_list = [x[:-4] for x in files]\n",
    "dataset_dict = {}\n",
    "\n",
    "for key in files_list : \n",
    "    print(key)\n",
    "    dataset_dict[key] = pd.read_csv('dataset/barra factor/' + key + '.csv', low_memory=False).set_index('date')\n",
    "    \n",
    "\"\"\"\n",
    "将日涨跌幅和市值也作为因子纳入因子dataframe的dict中去\n",
    "\"\"\"    \n",
    "for key in ['涨跌幅(%)', '总市值(元)']:\n",
    "    x = pd.read_csv('dataset/后复权数据-分类/' + key + '.csv', low_memory=False, encoding='gbk')\n",
    "    x = x.rename(columns = {\"日期\": \"date\"}).set_index('date')\n",
    "    x_columns = x.columns.to_list()\n",
    "    for i in range(len(x_columns)) : \n",
    "        if x_columns[i][:1] == '6' : \n",
    "            x_columns[i] = x_columns[i][:6] + '.XSHG'\n",
    "        else : \n",
    "            x_columns[i] = x_columns[i][:6] + '.XSHE'\n",
    "    x.columns = x_columns\n",
    "    if key == '涨跌幅(%)': key = 'ret'\n",
    "    if key == '总市值(元)': key = 'capital'\n",
    "    print(key)\n",
    "    dataset_dict[key] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T11:27:25.722652Z",
     "start_time": "2021-09-08T11:26:52.765Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "由于涨跌幅，市值和Barra因子来自不同的平台，这里对它们的股票和日期取交集，\n",
    "\"\"\"\n",
    "# 列取交集\n",
    "stks_sec = set()\n",
    "for key in dataset_dict.keys():\n",
    "    if len(stks_sec) == 0 : \n",
    "        stks_sec = set(dataset_dict[key].columns)\n",
    "    else: \n",
    "        stks_sec = set(dataset_dict[key].columns) & stks_sec\n",
    "stks_sec = sorted(list(stks_sec))\n",
    "for key in dataset_dict.keys():\n",
    "    dataset_dict[key] = dataset_dict[key][stks_sec]\n",
    "    \n",
    "# 行取交集\n",
    "dates = set()\n",
    "for key in dataset_dict.keys():\n",
    "    if len(dates) == 0 : \n",
    "        dates = set(dataset_dict[key].index)\n",
    "    dates = dates & set(dataset_dict[key].index)\n",
    "    print(len(dates))\n",
    "dates = sorted(list(dates))\n",
    "for key in dataset_dict.keys():\n",
    "    dataset_dict[key] = dataset_dict[key].loc[dates,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据去极值，标准化，中性化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T00:32:41.616609Z",
     "start_time": "2021-08-23T00:32:41.611191Z"
    }
   },
   "outputs": [],
   "source": [
    "def winsorize(factor_df):\n",
    "    \"\"\"\n",
    "    对因子值做去极值操作\n",
    "    :param factor_df: 因子值 (pandas.Dataframe类型),index为datetime, colunms为股票代码。\n",
    "                      形如:\n",
    "                                   AAPL\t　　　     BA\t　　　CMG\t　　   DAL\t      LULU\t　　\n",
    "                        date\n",
    "                        2016-06-24\t0.165260\t0.002198\t0.085632\t-0.078074\t0.173832\n",
    "                        2016-06-27\t0.165537\t0.003583\t0.063299\t-0.048674\t0.180890\n",
    "                        2016-06-28\t0.135215\t0.010403\t0.059038\t-0.034879\t0.111691\n",
    "                        2016-06-29\t0.068774\t0.019848\t0.058476\t-0.049971\t0.042805\n",
    "                        2016-06-30\t0.039431\t0.012271\t0.037432\t-0.027272\t0.010902\n",
    "    :return:去极值后的因子值(pandas.Dataframe类型),index为datetime, colunms为股票代码。\n",
    "    \"\"\"\n",
    "\n",
    "    def winsorize_series(se):\n",
    "        q = se.quantile([0.025, 0.975])\n",
    "        if isinstance(q, pd.Series) and len(q) == 2:\n",
    "            se[se < q.iloc[0]] = q.iloc[0]\n",
    "            se[se > q.iloc[1]] = q.iloc[1]\n",
    "        return se\n",
    "\n",
    "    def handle(rows):\n",
    "        return winsorize_series(rows[1])\n",
    "\n",
    "    result = pd.DataFrame(list(map(handle, factor_df.iterrows())), factor_df.index)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T00:32:41.623465Z",
     "start_time": "2021-08-23T00:32:41.617975Z"
    }
   },
   "outputs": [],
   "source": [
    "def standardize(factor_df):\n",
    "    \"\"\"\n",
    "    对因子值做z-score标准化\n",
    "    :param factor_df: 因子值 (pandas.Dataframe类型),index为datetime, colunms为股票代码。\n",
    "                      形如:\n",
    "                                   AAPL\t　　　     BA\t　　　CMG\t　　   DAL\t      LULU\t　　\n",
    "                        date\n",
    "                        2016-06-24\t0.165260\t0.002198\t0.085632\t-0.078074\t0.173832\n",
    "                        2016-06-27\t0.165537\t0.003583\t0.063299\t-0.048674\t0.180890\n",
    "                        2016-06-28\t0.135215\t0.010403\t0.059038\t-0.034879\t0.111691\n",
    "                        2016-06-29\t0.068774\t0.019848\t0.058476\t-0.049971\t0.042805\n",
    "                        2016-06-30\t0.039431\t0.012271\t0.037432\t-0.027272\t0.010902\n",
    "    :return:z-score标准化后的因子值(pandas.Dataframe类型),index为datetime, colunms为股票代码。\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def standardize_series(se):\n",
    "        se_std = se.std()\n",
    "        se_mean = se.mean()\n",
    "        return (se - se_mean) / se_std\n",
    "\n",
    "    def handle(rows):\n",
    "        return standardize_series(rows[1])\n",
    "\n",
    "    result = pd.DataFrame(list(map(handle, factor_df.iterrows())), factor_df.index)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T00:32:41.824382Z",
     "start_time": "2021-08-23T00:32:41.624922Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "将股票分类到其所属的不同行业下面，\n",
    "获得datafarme：res\n",
    "列为申万一级行业代码，行为0，1，2...，value为各个行业的成分股代码，\n",
    "有些行业成分股较少时，多出的行对应的valu为空值\n",
    "\"\"\"\n",
    "\n",
    "sector_list = pd.read_csv('D:/Python/Flies/Guanyun/barra/dataset/sector_list.csv',encoding='gbk',dtype=str)\n",
    "stock_list = pd.read_csv('D:/Python/Flies/Guanyun/A股数据/申万一级行业成份/' + '801740' +'.csv',dtype=str)['stock_code'].to_list()\n",
    "\n",
    "sector_content_df = pd.read_csv('D:/Python/Flies/Guanyun/barra/dataset/sector_content_df.csv').set_index('date')\n",
    "import re\n",
    "p = re.compile(r'(\\d+.[A-Z]+)')\n",
    "def findall_apply_func(y):\n",
    "    def findall_apply_inner_func(df_str,y) : \n",
    "        return p.findall(df_str)\n",
    "    return y.apply(findall_apply_inner_func, args=(y,))\n",
    "sector_content_df = sector_content_df.apply(findall_apply_func,axis=0)\n",
    "sector_content_df = sector_content_df.iloc[-1,:]\n",
    "res = pd.DataFrame()\n",
    "for sec in sector_content_df.index : \n",
    "    res = pd.concat([res,pd.DataFrame(sector_content_df[sec])],axis=1)\n",
    "res.columns = sector_content_df.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T00:32:41.874794Z",
     "start_time": "2021-08-23T00:32:41.870553Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取行业分类\n",
    "def get_industry_class(symbols):\n",
    "    \"\"\"\n",
    "    获取行业分类信息\n",
    "    :param symbols: 一组股票代码(list),形式为通用标准(编码.交易所 如[\"000001.XSHE\",\"600000.XSHG\"])\n",
    "    :return: sina的行业分类信息。(pandas.Dataframe) index为行业分类编号(1-49);columns为股票代码;值为0/1,分别表示属于该行业/不属于该行业\n",
    "    \"\"\"\n",
    "    sector_list = pd.read_csv('D:/Python/Flies/Guanyun/barra/dataset/sector_list.csv',encoding='gbk',dtype=str)\n",
    "    frame = pd.DataFrame(0,index = sector_content_df.index, columns = symbols)\n",
    "    for symbol in symbols:\n",
    "        this_class = res[res == symbol].dropna(axis=1,how=\"all\").columns[0]\n",
    "        frame.loc[this_class, symbol] = 1\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T00:32:41.944311Z",
     "start_time": "2021-08-23T00:32:41.876274Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from scipy.stats import rankdata\n",
    "# 行业、市值中性化 - 对Dataframe数据\n",
    "def neutralize( factor_df, factorIsMV = True):\n",
    "    \"\"\"\n",
    "    对因子做行业、市值中性化\n",
    "    :param factor_df: 因子值 (pandas.Dataframe类型),index为datetime, colunms为股票代码。\n",
    "                      形如:\n",
    "                                   AAPL\t　　　     BA\t　　　CMG\t　　   DAL\t      LULU\t　　\n",
    "                        date\n",
    "                        2016-06-24\t0.165260\t0.002198\t0.085632\t-0.078074\t0.173832\n",
    "                        2016-06-27\t0.165537\t0.003583\t0.063299\t-0.048674\t0.180890\n",
    "                        2016-06-28\t0.135215\t0.010403\t0.059038\t-0.034879\t0.111691\n",
    "                        2016-06-29\t0.068774\t0.019848\t0.058476\t-0.049971\t0.042805\n",
    "                        2016-06-30\t0.039431\t0.012271\t0.037432\t-0.027272\t0.010902\n",
    "    :param factorIsMV: 待中性化的因子是否是市值类因子(bool)。是则为True,默认为False\n",
    "    :return: 中性化后的因子值(pandas.Dataframe类型),index为datetime, colunms为股票代码。\n",
    "    \"\"\"\n",
    "\n",
    "#     # 剔除有过多无效数据的个股   # 回看固定时间\n",
    "#     empty_data = pd.isnull(factor_df).sum()\n",
    "#     pools = empty_data[empty_data < len(factor_df) * 0.1].index  # 保留空值比例低于0.1的股票\n",
    "#     factor_df = factor_df.loc[:, pools]\n",
    "\n",
    "    # 剔除过多值为空的截面\n",
    "    factor_df = factor_df.dropna(thresh = len(factor_df.columns) * 0.5) # 保留空值比例低于0.9的截面\n",
    "\n",
    "    # 获取行业分类信息\n",
    "#     X = get_industry_class(pools)\n",
    "    X = get_industry_class(factor_df.columns.to_list())\n",
    "    nfactors = len(X.index)\n",
    "\n",
    "    # 获取对数流动市值，并去极值、标准化。市值类因子不需进行这一步\n",
    "    if not factorIsMV:\n",
    "        x1 = standardize(winsorize(read_LFLO(pools, factor_df.index[0], factor_df.index[-1])))\n",
    "        nfactors += 1\n",
    "\n",
    "    result = []\n",
    "    # 逐个截面进行回归，留残差作为中性化后的因子值\n",
    "    for i in factor_df.index:\n",
    "        if not factorIsMV:\n",
    "            DataAll = pd.concat([X.T, x1.loc[i], factor_df.loc[i]], axis=1)\n",
    "        else:\n",
    "            DataAll = pd.concat([X.T, factor_df.loc[i]], axis=1)\n",
    "        # 剔除截面中值含空的股票\n",
    "        DataAll = DataAll.dropna()\n",
    "        DataAll.columns = list(range(0, nfactors + 1))\n",
    "        regr = linear_model.LinearRegression(fit_intercept=False)\n",
    "        regr.fit(np.matrix(DataAll.iloc[:, 0:nfactors]), np.transpose(np.matrix(DataAll.iloc[:, nfactors])))\n",
    "        residuals = np.transpose(np.matrix(DataAll.iloc[:, nfactors])) -regr.predict(np.matrix(DataAll.iloc[:, 0:nfactors]))\n",
    "        residuals = pd.DataFrame(data=residuals, index=np.transpose(np.matrix(DataAll.index.values)))\n",
    "        residuals.index = DataAll.index.values\n",
    "        residuals.columns = [i]\n",
    "        result.append(residuals)\n",
    "\n",
    "    result = pd.DataFrame(pd.concat(result, axis=1).T)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T00:32:46.843854Z",
     "start_time": "2021-08-23T00:32:41.946046Z"
    }
   },
   "outputs": [],
   "source": [
    "sec_df = pd.DataFrame(index=dates, columns=stks_sec)\n",
    "for stock in sec_df.columns:\n",
    "    sec_df[stock] = res[res == stock].dropna(how = 'all', axis = 1).columns[0]\n",
    "dataset_dict['industry'] = sec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T04:31:49.995414Z",
     "start_time": "2021-08-23T00:34:43.699803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-06-08\n",
      "====================================================\n",
      "2015-07-08\n",
      "====================================================\n",
      "2015-08-06\n",
      "====================================================\n",
      "2015-09-08\n",
      "====================================================\n",
      "2015-10-14\n",
      "====================================================\n",
      "2015-11-12\n",
      "====================================================\n",
      "2015-12-11\n",
      "====================================================\n",
      "2016-01-12\n",
      "====================================================\n",
      "2016-02-17\n",
      "====================================================\n",
      "2016-03-17\n",
      "====================================================\n",
      "2016-04-18\n",
      "====================================================\n",
      "2016-05-18\n",
      "====================================================\n",
      "2016-06-20\n",
      "====================================================\n",
      "2016-07-19\n",
      "====================================================\n",
      "2016-08-17\n",
      "====================================================\n",
      "2016-09-19\n",
      "====================================================\n",
      "2016-10-25\n",
      "====================================================\n",
      "2016-11-23\n",
      "====================================================\n",
      "2016-12-22\n",
      "====================================================\n",
      "2017-01-23\n",
      "====================================================\n",
      "2017-02-28\n",
      "====================================================\n",
      "2017-03-29\n",
      "====================================================\n",
      "2017-05-02\n",
      "====================================================\n",
      "2017-06-02\n",
      "====================================================\n",
      "2017-07-03\n",
      "====================================================\n",
      "2017-08-01\n",
      "====================================================\n",
      "2017-08-30\n",
      "====================================================\n",
      "2017-09-28\n",
      "====================================================\n",
      "2017-11-03\n",
      "====================================================\n",
      "2017-12-04\n",
      "====================================================\n",
      "2018-01-03\n",
      "====================================================\n",
      "2018-02-01\n",
      "====================================================\n",
      "2018-03-09\n",
      "====================================================\n",
      "2018-04-11\n",
      "====================================================\n",
      "2018-05-14\n",
      "====================================================\n",
      "2018-06-12\n",
      "====================================================\n",
      "2018-07-12\n",
      "====================================================\n",
      "2018-08-10\n",
      "====================================================\n",
      "2018-09-10\n",
      "====================================================\n",
      "2018-10-17\n",
      "====================================================\n",
      "2018-11-15\n",
      "====================================================\n",
      "2018-12-14\n",
      "====================================================\n",
      "2019-01-16\n",
      "====================================================\n",
      "2019-02-21\n",
      "====================================================\n",
      "2019-03-22\n",
      "====================================================\n",
      "2019-04-23\n",
      "====================================================\n",
      "2019-05-27\n",
      "====================================================\n",
      "2019-06-26\n",
      "====================================================\n",
      "2019-07-25\n",
      "====================================================\n",
      "2019-08-23\n",
      "====================================================\n",
      "2019-09-24\n",
      "====================================================\n",
      "2019-10-30\n",
      "====================================================\n",
      "2019-11-28\n",
      "====================================================\n",
      "2019-12-27\n",
      "====================================================\n",
      "2020-02-05\n",
      "====================================================\n",
      "2020-03-05\n",
      "====================================================\n",
      "2020-04-03\n",
      "====================================================\n",
      "2020-05-08\n",
      "====================================================\n",
      "2020-06-08\n",
      "====================================================\n",
      "2020-07-09\n",
      "====================================================\n",
      "2020-08-07\n",
      "====================================================\n",
      "2020-09-07\n",
      "====================================================\n",
      "2020-10-14\n",
      "====================================================\n",
      "2020-11-12\n",
      "====================================================\n",
      "2020-12-11\n",
      "====================================================\n",
      "2021-01-12\n",
      "====================================================\n",
      "2021-02-10\n",
      "====================================================\n",
      "2021-03-18\n",
      "====================================================\n",
      "2021-04-19\n",
      "====================================================\n",
      "2021-05-21\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'2021-05-21' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-1f64334f85ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock_list_df_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdataset_dict_500\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdates_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock_list_df_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#     print(dates_index-252)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdates_500\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdates_index\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m505\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdates_index\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: '2021-05-21' is not in list"
     ]
    }
   ],
   "source": [
    "for t in range(71, len(stock_list_df_final.index)) : \n",
    "    print(stock_list_df_final.index[t])\n",
    "    dataset_dict_500 = {}\n",
    "    dates_index = dates.index(stock_list_df_final.index[t])\n",
    "    dates_500 = dates[dates_index-505:dates_index-1]\n",
    "    stks_500 = stock_list_df_final.iloc[t,:].to_list()\n",
    "    while np.nan in stks_500:\n",
    "        stks_500.remove(np.nan)\n",
    "\n",
    "    for key in dataset_dict.keys() : \n",
    "        if key in files_list : \n",
    "            dataset_dict_500[key] = neutralize(standardize(winsorize(dataset_dict[key].loc[dates_500, stks_500])), factorIsMV = True)\n",
    "        else : \n",
    "            dataset_dict_500[key] = dataset_dict[key].loc[dates_500, stks_500]\n",
    "\n",
    "    dataset_stks_df = pd.DataFrame(columns = ['date','stocknames'] + list(dataset_dict_500.keys()))\n",
    "    for stocknames in stks_500:\n",
    "        dataset_stks_df = dataset_stks_df.append([{'stocknames':stocknames}], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "    dataset_df_sum = pd.DataFrame()\n",
    "    interval = 50\n",
    "    for i in range(len(dates_500)) : \n",
    "        tmp_df = copy.deepcopy(dataset_stks_df)\n",
    "        tmp_df = tmp_df.set_index('stocknames')\n",
    "        tmp_df['date'] = dates_500[i]\n",
    "        for key in dataset_dict_500.keys() : \n",
    "            try:\n",
    "                tmp_df[key] = pd.DataFrame(dataset_dict_500[key].loc[dates_500[i]]).sort_index()\n",
    "            except:\n",
    "                pass\n",
    "        tmp_df['stocknames'] = tmp_df.index\n",
    "        tmp_df = tmp_df.reset_index(drop=True)        \n",
    "\n",
    "        if len(dataset_df_sum) == 0 : \n",
    "            dataset_df_sum = copy.deepcopy(tmp_df)\n",
    "        else: \n",
    "            dataset_df_sum = pd.concat([dataset_df_sum, tmp_df],axis=0)\n",
    "\n",
    "    print('====================================================')\n",
    "\n",
    "    dataset_df_sum['size'] = 1.0 * dataset_df_sum['lncap']\n",
    "    dataset_df_sum['beta'] = 1.0 * dataset_df_sum['beta']\n",
    "    dataset_df_sum['momentum'] = 1.0 * dataset_df_sum['rstr']\n",
    "    dataset_df_sum['residual_volatility'] = 0.74 * dataset_df_sum['dastd'] + 0.16 * dataset_df_sum['cmra'] + 0.10 * dataset_df_sum['hsigma']\n",
    "    dataset_df_sum['non_linear_size'] = 1.0 * dataset_df_sum['nlsize']\n",
    "    dataset_df_sum['book_to_price_ratio'] = 1.0 * dataset_df_sum['btop']\n",
    "    dataset_df_sum['liquidity'] = 0.35 * dataset_df_sum['stom'] + 0.35 * dataset_df_sum['stoq'] + 0.30 * dataset_df_sum['stoa']\n",
    "    dataset_df_sum['earnings_yield'] = 0.68 * dataset_df_sum['epfwd'] + 0.21 * dataset_df_sum['cetop'] + 0.11 * dataset_df_sum['etop']\n",
    "    dataset_df_sum['growth'] = 0.18 * dataset_df_sum['egrlf'] + 0.11 * dataset_df_sum['egrsf'] + 0.24 * dataset_df_sum['egro'] + 0.47 * dataset_df_sum['sgro']\n",
    "    dataset_df_sum['leverage'] = 0.38 * dataset_df_sum['mlev'] + 0.35 * dataset_df_sum['dtoa'] + 0.27 * dataset_df_sum['blev']\n",
    "    dataset_df_sum = dataset_df_sum.drop([ 'blev', 'btop', 'cetop', 'cmra', 'dastd', 'dtoa',\n",
    "           'egrlf', 'egro', 'egrsf', 'epfwd', 'etop', 'hsigma', 'lncap', 'mlev',\n",
    "           'nlsize', 'rstr', 'sgro', 'stoa', 'stom', 'stoq'],axis=1)\n",
    "    dataset_df_sum = dataset_df_sum[[\n",
    "        'date', 'stocknames', 'capital', 'ret', 'industry', 'size', 'beta',\n",
    "        'momentum', 'residual_volatility', 'non_linear_size',\n",
    "        'book_to_price_ratio', 'liquidity', 'earnings_yield', 'growth', 'leverage'\n",
    "    ]]    \n",
    "\n",
    "    dataset_df_sum.to_csv('dataset/barra processing/total data/' + 'barra_data_' + str(t) + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
